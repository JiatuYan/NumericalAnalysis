\documentclass[twoside,a4paper]{article}
\usepackage{geometry}
\geometry{margin=1.5cm, vmargin={0pt,1cm}}
\setlength{\topmargin}{-1cm}
\setlength{\paperheight}{29.7cm}
\setlength{\textheight}{25.3cm}

% useful packages.
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{enumerate}
\usepackage{float}
\usepackage{graphicx}
\usepackage{multicol}
\usepackage{fancyhdr}
\usepackage{layout}

% some common command
\newcommand{\dif}{\mathrm{d}}
\newcommand{\avg}[1]{\left\langle #1 \right\rangle}
\newcommand{\difFrac}[2]{\frac{\dif #1}{\dif #2}}
\newcommand{\pdfFrac}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\OFL}{\mathrm{OFL}}
\newcommand{\UFL}{\mathrm{UFL}}
\newcommand{\fl}{\mathrm{fl}}
\newcommand{\op}{\odot}
\newcommand{\Eabs}{E_{\mathrm{abs}}}
\newcommand{\Erel}{E_{\mathrm{rel}}}

\begin{document}

\pagestyle{fancy}
\fancyhead{}
\lhead{NAME Jiatu Yan}
\chead{Numerical Analysis homework \#1}
\rhead{Date 2020.3.14}


\section*{I. \small{Consider the bisection method starting with the initial interval $[1.5,3.5]$}}

\subsection*{I-a \small{What is the width of the interval at the $n$th step?}} 

Suppose the interval at the $n$th step is $[a_{n},b_{n}],n\in\mathbb{N}$. 
Since $b_{n}-a_{n}=\frac{1}{2}(b_{n+1}-a_{n+1}), b_{0}-a_{0}=3.5-1.5=2$, 
by recursion we can have that $\forall n\in\mathbb{N}$, the width of the $n$th interval $l=\frac{1}{2^{n-1}}$.
 
\subsection*{I-b \small{What is the maximum possible distance between the root r and the midpoint of the interval?}}

We assume that $d_{n}$ as the distance between r and the midpoint of $[a_{n}, b_{n}]$.  

If  $a_{n}\neq a_{0}, b_{n}\neq b_{0}$, which means $\exists s<n$, $a_{n}$ is the mid point of $[a_{s},b_{s}]$
, and $\exists t<n$, $b_{t}$ is the mid point of $[a_{t}, b_{t}]$. Thus, r $\in \left( a_{n},b_{n} \right) $ 
, which means $\exists \epsilon>0 , r+\epsilon<b_{n},r-\epsilon>a_{n}$. So $d_{n}= \mid r-\frac{b_{n}+a_{n}}{2} \mid \le
 \mid \frac{b_{n}-a_{n}}{2}-\epsilon \mid = \mid \frac{1}{2^{n}}-\epsilon \mid $
 . 
 
 If $b_{n}=b_{0}$, which means $\forall m<n, r>\frac{b_{m}+a_{m}}{2}$, if $r=b_{0}$, $d_{n} = \frac{1}{2^{n}}$, or 
 the same as the situation above, $\exists \epsilon>0, d_{n}=  \mid \frac{1}{2^{n}}-\epsilon \mid $.
 
 If $a_{n}=a_{0}$, the consequence is similar as that when $b_{n}=b_{0}$.
 
 So we have $d_{n} \le  \mid \frac{1}{2^{n}}-\epsilon$ or $d_{n}=\frac{1}{2_n}$, which means the maximum possible distance
 between r and the midpoint of the interval $[a_{n}, b_{n}]$ is $\frac{1}{2^{n}}$ 
 \section*{II. \small{Prove that the number of the step n must satisfy $n\ge \frac{\log(b_{0}-a_{0})-\log\epsilon-\log a_0}{\log2}-1$}}

We have proved in the first section that 
$d_{n}\le \frac{b_0-a_0}{2^{n+1}}$. In order to determine the root with its relative error no greater that $\epsilon$, 
we have $\frac{d_{n}}{r}\le \frac{b_0-a_0}{r2^{n+1}}\le \frac{b_0-a_{0}}{a_{0}2^{n+1}}\le \epsilon$.

Thus, $b_0-a_0\le 2^{n}a_0\epsilon$, 
take $\log_2$ on both side we have $\log_{b_0-a_0}\le \log 2(n+1)+\log\epsilon+\log a_0$
, sort it we have $n\ge \frac{\log\left(b_0-a_0\right)-\log\epsilon-\log a_0 }{\log 2}-1$ 
, so we have proved the it.


\section*{III. \small{Perform four iterations of Newton's method}}

$p\left( x \right)=4x^3-2x^2+3$, we have $p'\left( x \right) =12x^2-4x$
, by $x_{n+1}=x_{n}-\frac{f\left( x_{n}\right) }{f'\left( x_{n} \right) }
, n\in\mathbb{N}$. 
So we can calculate each $x_{n}$ with a handy calculator. 

\begin{tabular}{|l|c|c|c|c|c|}
\hline
n&0&1&2&3&4\\
\hline
$x_{n}$ &-1&$-0.8125$ &$-0.7708041958$&$-0.7688323843$&$-0.7688280859$\\
\hline 
\end{tabular}

\section*{IV. \small{Consider a variation of Netwon's method $x_{n+1}=x_{n}-\frac{f\left( x_{N} \right) }{f'\left( x_0\right) }$
, find C and s such that $e_{n+1}=Ce_{n}^{s}$.}}

Do not lose the generality, we can assume that the root $\alpha<x_0
, f\left(  \alpha\right)=0, f'\left( x\right)>0 \forall x\in \left( \alpha,x_0\right) $ .
Thus, we have $\alpha<x_{n+1}< x_{n}\le x_0, \forall n\in\mathbb{N}$.	

By Taylor's theorem we have
 \[
	 f\left( x_{n} \right)=f\left( \alpha \right)+
	 f'\left(  \xi\right)\left( x_{n}-\alpha \right) 
	 ,\left(  \xi\in\left(  \alpha,x_{n}\right) \right)  
 .\] 
Thus, we have
\[
	e_{n+1}=e_{n}-\frac{f\left( x_{n} \right) }{f'_{x_0}}=
	e_{n}\left(  \frac{f'_{x_0}-f'\left( \xi \right) }{f'_{x_0}}\right)
	\le e_{n}\left(  \frac{2f'\left( x_0 \right) }{f'\left( x_0 \right) }\right) 
	=2e_{n}
.\] 
Thus we take the C and s.
\section*{V. \small{Within $\left( -\frac{\pi}{2},\frac{\pi}{2}\right) $
, will the iteration $x_{n+1}=tan^{-1}x_{n} converge?$}}

By the symmetry of $tanx$ and x, we can suppose that  $\{x_{n}\}$ 
converges to a positive number $\alpha$.

Since  $1-\frac{1}{tan1}>0$, $0.5-\frac{1}{tan_0.5}<0$, and the continuity of $x-\frac{1}{tanx}$
, we have that there exists one $\alpha$,  $\alpha=\frac{1}{tan\alpha}$.
If $x_{0}=\alpha$, it is obvious that $\{x_{n}\}$ is convergent.

If $x_{0}\neq \alpha$.
We suppose that $\{x_{n}\}$ is convergent, so $\{x_{n}\}$ will converge to $\alpha$.
Then we take a sufficiently small $\epsilon$, that  $\exists n$ s.t. $ \mid x_{n+1}-x_{n}=\epsilon \mid $
, then we have 
\[
 \mid x_{n+2}-x_{n+1} \mid =  \mid \frac{1}{tan\frac{1}{tanx_{n}}}-\frac{1}{tanx_{n}} \mid 
 > \mid \frac{tan\frac{1}{tanx_{n}}-tanx_{n}}{1+tanx_{n}tan\frac{1}{tanx_{n}}} \mid
 > \mid tan\left(  x_{n}-\frac{1}{tanx_{n}}\right)  \mid
 > \mid x_{n}-x_{n+1} \mid>\epsilon
.\] 
Thus we have $\forall m>n,  \mid  x_{m+1}-x_{m}\mid> \mid  x_{n+1}-x_{n}\mid  $ 
, which contradicts to the convergence of $\{x_{n}\}$.

So $\{x_{n}\}$ is convergent iff $x_{0}=\pm\alpha$.

\section*{VI. \small{Let $p>1$. What is the value 
of $x=\frac{1}{p+\frac{1}{p+\frac{1}{p+\ldots}}}$}}

Suppose $x_0=0, x_{n+1}=\frac{1}{p+x_{n}}, \forall n\in\mathbb{N}$.
Now we prove that $\{x_{n}\}$ is convergent.

When n=1, it is obvious that $\frac{1}{p+\frac{1}{p}}=x_2<x_1=\frac{1}{p}$.

Suppose when $n=k\left(  k\ge 1\right) $, $x_{n+1}<x_{n}$
. Then, $x_{n+2}=\frac{1}{p+x_{n+1}}<\frac{1}{p+x_{n}}=x_{n+1}$.
So we have $\forall n\in \mathbb{N}^{+}, x_{n+1}<x_{n}$.
Because $\forall n\in\mathbb{N}^{+}, x_{n}>0$, we have $\{x_{n}\}$ is convergent.

To get the value of x, we take a function $f\left( x\right)=\frac{1}{p+x} $
, $x_{n}=f\left( x_{n+1} \right) $, when $n\to \infty, x_{n}\to x$.
So $\forall \epsilon>0, \exists N, \forall n>N, x_{n}-x<\epsilon$
, which also means $f\left( x_{n}\right)-x_{n}<\epsilon$.
Since we have proved that $\{x_{n}\}$ is convergent, by the randomization of $\epsilon$, we get that  $x$ is the root of  $f\left(  x\right)-x=0$
, which is $x^2+px-1=0$. Because $\bigtriangleup=p^2+4>0$, the root is always exist. By formula method and $x>0$, we have $x=\frac{-p+\sqrt{p^2+4} }{2}$.

\section*{VII. What happens in problem II if $a_0<0<b_0$}

We assume that $c=min\{-a_0, b_0\}$.

If $r\neq 0$, indorer to determine that relative error no greater than $\epsilon$
, we have $ \frac{d_{n}}{r}\le \frac{b_{0}-a_{0}}{r2^{n+1}}
\le \frac{b_0-a_0}{c2^{n+1}}<\epsilon$.
Thus, the same as the inequality we have in II, we have
$n\ge \frac{\log\left( b_0-a_0 \right)-\log\epsilon-\log c }{\log 2}-1$.

If $r=0$, the relative error is not defined, so it is not so appropriate 
when  $a_0<0<b_0$. But if we want to determine the error no greater than $\epsilon$
, we have  $d_{n}=\frac{b_0-a_0}{2^{n+1}}\le \epsilon$, thus we get 
$n\ge \frac{\log\left( b_0-a_0 \right)-\log \epsilon }{\log 2}-1$.

\section*{VIII. Consider solving $f\left( x \right)=0 $ by Newton's method}

\subsection*{VIII-a \small{How can a multiple zero be detected by examining the behavior of the points $x_{n}, f\left( x_{n} \right)?$}}

Since $f^{\left( k \right)\neq 0 }$, by taking $x_0$ sufficiently close to $\alpha$
, we have $ \mid  x_{n+1}-\alpha \mid < \mid x_{n}-\alpha \mid $.
By Taylor's theorem we have, 
\[
	f\left( x_{n}\right)=\sum_{n=0}^{\infty} 
	\frac{f^{\left( n\right) }\left(  \alpha\right)\left( x_{n}-\alpha\right)^{n}  }{n!} 
.\] 
Because $f^{i}\left( \alpha \right) =0\left(  i<k\right) $, we have
\[
	f\left( x_{n}\right)=\sum_{n=k}^{\infty} 
	\frac{f^{\left( n \right) }\left(  \alpha\right)\left( x_{n}-\alpha\right)^{n}  }{n!}
	=O\left( (x_{n}-\alpha)^{k} \right) 
.\] 
So if 
\[
	\forall a>0 , \exists N\in\mathbb{N}, \forall n>N
	, \mid f\left( x_{n} \right) \mid <  \mid a\left( x-\alpha \right)^k   \mid        
.
\]
Which means the ${f\left( x_n \right) }$ converge to  $f
\left( \alpha \right) $ in order k, so we can detect a multiple zero.

\subsection*{VIII-b. \small{Prove that if r is a zero of multiplicity k
, quadratic convergence in Newton's iteration will be restored by 
$x_{n+1}=x_{n}-k\frac{f\left( x_{n} \right) }{f'{x_{n}}}$}}

Do not lose the generality, we can suppose that $f'\left( \alpha \right)>0 $
, $x_{n}>\alpha$

By Taylor's theorem, we have 
\[
	f\left( x_{n}\right)=\frac{1}{k!}
	\left( x_{n}-\alpha \right)^{\left( k \right) }f^{k}\left( \alpha \right)
	+\frac{1}{k+1!}
	\left( x_{n}-\alpha \right)^{k+1}f^{\left( k+1 \right) }\left(  \xi\right)  
	\left( \xi\in\left( \alpha, x_{n} \right)  \right) 
.\] 
and
\[
	f'\left( x_{n} \right)=\frac{1}{k-1!}
	\left(  x_{n}-\alpha\right)^{k-1}f^{\left( k-1 \right) }\left( \alpha \right)
	+\frac{1}{k!}
	\left( x_{n}-\alpha \right)^{k}f^{\left( k \right) }\left( \eta\right)  
	\left( \eta\in\left( \alpha, x_{n} \right)  \right) 
.\] 
So by the iteration $x_{n+1}=x_{n}-k\frac{f\left( x_{n} \right) }{f'\left( x_{n} \right) }$, we have
\[
e_{n+1}=\frac{\frac{1}{k!}{e_{n}}^{k}f^{\left(  k\right) }\left( \alpha \right)
+\frac{1}{k!k}{e_{n}}^{k+1}f^{\left( k+1 \right)}\left( \eta \right) 
-\frac{1}{k!}{e_{n}}^{k}f^{\left(  k\right) }\left( \alpha \right)
-\frac{1}{k+1!}{e_{n}}^{k+1}f^{\left( k+1 \right)}\left( \xi \right) 
}
{\frac{1}{k!}{e_{n}}^{k-1}f^{\left( k \right) }\left( \alpha\right) 
+\frac{1}{k!k}{e_{n}}^{k}f^{\left( k+1 \right)}\left( \eta \right) }
.\] 
\[
\frac{e_{n+1}}{e_{n}^{2}}=\frac
{\frac{1}{k!k}f^{\left( k+1 \right)}\left( \eta \right) 
-\frac{1}{k+1!}f^{\left( k+1 \right)}\left( \xi \right) 
}
{\frac{1}{k!}f^{\left( k \right) }\left( \alpha\right) 
+\frac{1}{k!k}{e_{n}}f^{\left( k+1 \right)}\left( \eta \right) }
.\] 
Because $\lim_{n\to\infty}e_{n}=0$
, $ \mid f^{\left( k+1 \right) }\left(  \xi\right)  \mid 
< \mid f^{\left(  k+1\right) }\left( \alpha \right)  \mid $
, $ \mid f^{\left( k+1 \right) }\left(  \xi\right)  \mid 
< \mid f^{\left(  k+1\right) }\left( \alpha \right)  \mid $, we have
\[
 \mid \frac{e_{n+1}}{e_{n}^2} \mid 
 \le  \mid \frac{2f^{\left( k+1 \right) }\left(  \alpha\right) }
{kf^{\left( k\right) }\left( \alpha \right) } \mid = C 
.\] 
So we have proved that the modified iteration is quadratic convergence.

\end{document}

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: t
%%% End: 
